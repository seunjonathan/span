{
	"name": "PL_BEAVERLABS_UTC_Times",
	"properties": {
		"description": "This pipeline was migrated from the EDW pipeline called PL_TOPS_BEAVERLABS_API.\n\nIt's purpose is to build a table of scheduled arrival and departure times in UTC. The consumer of this data is the BeaverLabs Web App. The requirement for UTC times was added by ticket #1639\n\nIn this pipeline, a SQL query against the TOPS SQL server is used to  land parquet data in bronze/BEAVERLABS/UTC_TIMES which a PySpark activity then converts to delta and persists to silver/BEAVERLABS/UTC_TIMES\n\nTech debt: This functionality within this pipeline could possibly be subsumed by the BeaverLabs web app. As such the introduction/use of this pipeline adds to our technical debt load.",
		"activities": [
			{
				"name": "BeaverLabs",
				"description": "This activity runs a SQL query directly against the TOPS server.",
				"type": "Copy",
				"dependsOn": [
					{
						"activity": "Reset Landing Folders",
						"dependencyConditions": [
							"Succeeded"
						]
					}
				],
				"policy": {
					"timeout": "7.00:00:00",
					"retry": 0,
					"retryIntervalInSeconds": 30,
					"secureOutput": false,
					"secureInput": false
				},
				"userProperties": [],
				"typeProperties": {
					"source": {
						"type": "SqlServerSource",
						"sqlReaderQuery": "SELECT Distinct  assignment.pk_Assignment_in 'Sailing_ID'\n,DATEADD(dd, 2, appointment.StartDate_dt + StartTime_dt) 'Scheduled_Departure_Date_Time'\n,DATEADD (hh\n          ,CASE WHEN (SELECT COUNT(*)  FROM t_bts_timezone WHERE DATEADD(dd, 2, appointment.StartDate_dt + StartTime_dt) between dststart AND dstend)  \n                    =1 THEN 7\n                       ELSE 8\n                       END\n          ,DATEADD(dd, 2, appointment.StartDate_dt + StartTime_dt)) 'UTC_Scheduled_Departure_Date_Time'\n,assignment.DepartureTime_dt 'Actual_Departure_Date_Time'\n,DATEADD (hh\n          ,CASE WHEN (SELECT COUNT(*)  FROM t_bts_timezone WHERE assignment.DepartureTime_dt between dststart AND dstend)  \n                    =1 THEN 7\n                       ELSE 8\n                       END\n         , assignment.DepartureTime_dt) 'UTC_Actual_Departure_Date_Time'\n         ,assignment.LatestETA_dt 'ETA'\n,DATEADD (hh\n          ,CASE WHEN (SELECT COUNT(*)  FROM t_bts_timezone WHERE assignment.LatestETA_dt between dststart AND dstend)  \n                    =1 THEN 7\n                       ELSE 8\n                       END\n         ,assignment.LatestETA_dt) 'UTC_ETA'\n,DATEADD(dd, 2, appointment.EstimatedEndDate_dt + EstimatedEndTime_dt) 'Scheduled_Arrival_Date_Time'\n,DATEADD (hh\n          ,CASE WHEN (SELECT COUNT(*)  FROM t_bts_timezone WHERE DATEADD(dd, 2, appointment.EstimatedEndDate_dt + EstimatedEndTime_dt) between dststart AND dstend)  \n                    =1 THEN 7\n                       ELSE 8\n                       END\n          ,DATEADD(dd, 2, appointment.EstimatedEndDate_dt + EstimatedEndTime_dt)) 'UTC_Scheduled_Arrival_Date_Time'\n,DATEADD(dd, 2, appointment.EndDate_dt + appointment.EndTime_dt) 'Actual_Arrival_Date_Time'\n,DATEADD (hh\n          ,CASE WHEN (SELECT COUNT(*)  FROM t_bts_timezone WHERE DATEADD(dd, 2, appointment.EndDate_dt + appointment.EndTime_dt) between dststart AND dstend)  \n                    =1 THEN 7\n                       ELSE 8\n                       END\n          ,DATEADD(dd, 2, appointment.EndDate_dt + appointment.EndTime_dt)) 'UTC_Actual_Arrival_Date_Time'\n,assignment.Deleted_dt 'Deleted_Date'\n,assignment.LastUpdate_ts 'Assignment_lastupdate_ts'\n,appointment.LastUpdate_ts 'Appointment_lastupdate_ts'\nFROM t_Assignment assignment\nINNER JOIN t_Appointment appointment ON appointment.pk_Appointment_in = assignment.fk_Appointment_in\nINNER JOIN t_Assignment_MasterLog assignmentmasterlog ON assignment.pk_Assignment_in = assignmentmasterlog.fk_Assignment_in\nWHERE YEAR(assignment.Added_dt)>2021 ",
						"queryTimeout": "02:00:00",
						"partitionOption": "None"
					},
					"sink": {
						"type": "ParquetSink",
						"storeSettings": {
							"type": "AzureBlobFSWriteSettings",
							"copyBehavior": "PreserveHierarchy"
						},
						"formatSettings": {
							"type": "ParquetWriteSettings"
						}
					},
					"enableStaging": false,
					"translator": {
						"type": "TabularTranslator",
						"typeConversion": true,
						"typeConversionSettings": {
							"allowDataTruncation": true,
							"treatBooleanAsNumber": false
						}
					}
				},
				"inputs": [
					{
						"referenceName": "DS_TOPS_SQL",
						"type": "DatasetReference",
						"parameters": {
							"Server": "van-ss-sql15ag.seaspan.com",
							"Database": "TOPSSEASPAN_PROD",
							"pUsername": "PowerBIReader_SMCBITeam",
							"pSecretname": "TOPS-Password"
						}
					}
				],
				"outputs": [
					{
						"referenceName": "DS_Archive_Parquet",
						"type": "DatasetReference",
						"parameters": {
							"pContainer": "landing",
							"pDirectory": "bronze/BEAVERLABS/UTC_TIMES"
						}
					}
				]
			},
			{
				"name": "Reset Landing Folders",
				"description": "Empty the landing folders so we don't re-process the same data twice (though it shouldn't matter since the data is upserted).",
				"type": "Delete",
				"dependsOn": [],
				"policy": {
					"timeout": "7.00:00:00",
					"retry": 0,
					"retryIntervalInSeconds": 30,
					"secureOutput": false,
					"secureInput": false
				},
				"userProperties": [],
				"typeProperties": {
					"dataset": {
						"referenceName": "DS_Archive_JSON",
						"type": "DatasetReference",
						"parameters": {
							"pContainer": "landing",
							"pDirectory": "bronze/BEAVERLABS/UTC_TIMES"
						}
					},
					"enableLogging": false,
					"storeSettings": {
						"type": "AzureBlobFSReadSettings",
						"recursive": true,
						"enablePartitionDiscovery": false
					}
				}
			},
			{
				"name": "Curate Parquet",
				"description": "This pyspark script will copy incoming parquet file and upsert the contents into the delta lake.",
				"type": "DatabricksSparkPython",
				"dependsOn": [
					{
						"activity": "BeaverLabs",
						"dependencyConditions": [
							"Succeeded"
						]
					}
				],
				"policy": {
					"timeout": "0.12:00:00",
					"retry": 0,
					"retryIntervalInSeconds": 30,
					"secureOutput": false,
					"secureInput": false
				},
				"userProperties": [],
				"typeProperties": {
					"pythonFile": "dbfs:/FileStore/pyspark-scripts/curate_parquet.py",
					"parameters": [
						"-tUTC_TIMES",
						"-sbronze",
						"-dsilver",
						"-vBEAVERLABS",
						"-kSailing_ID",
						"-j[{\"table_name\":\"\",\"renaming_instructions\":\"\"}]",
						"-iy",
						"-a[{\"error_message\":\"\",\"validation_command\":\"\"}]"
					]
				},
				"linkedServiceName": {
					"referenceName": "LS_SMG_DBW",
					"type": "LinkedServiceReference"
				}
			}
		],
		"folder": {
			"name": "BEAVERLABS"
		},
		"annotations": [],
		"lastPublishTime": "2024-01-29T21:59:27Z"
	},
	"type": "Microsoft.DataFactory/factories/pipelines"
}